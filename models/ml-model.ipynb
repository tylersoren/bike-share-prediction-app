{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ride Counts for a Bike Sharing System\n",
    "\n",
    "We are going to explore data from a bike sharing system and correlate it with weather data to try to predict demand. This can help the business make important decisions on inventory, staffing, and sales forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep\n",
    "The following Python modules need to be available. Instal with pip or conda\n",
    "\n",
    "* matplotlib - chart visualization\n",
    "* seaborn - enhancement to charting using matplotlib\n",
    "* numpy - mathematical and statistics functions\n",
    "* pandas - data manipulation and exploration\n",
    "* tensorflow - machine learning\n",
    "\n",
    "Once installed you can import the libraries and validate that the tensorflow version is 2.x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os, math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare data source and destination paths\n",
    "raw_data_subdir = '..\\\\data\\\\raw'\n",
    "weather_file = 'weather2015-2017.csv'\n",
    "bike_file_suffix = 'capitalbikeshare-tripdata.csv'\n",
    "\n",
    "clean_data_subdir = '..\\\\data\\\\prepared'\n",
    "clean_weather_file = 'weather.csv'\n",
    "clean_transaction_file = 'bike_transactions.csv'\n",
    "clean_hourly_ride_file = 'hourly_rides.csv'\n",
    "\n",
    "raw_data_dir = os.path.join(os.getcwd(), raw_data_subdir)\n",
    "clean_data_dir = os.path.join(os.getcwd(), clean_data_subdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Weather Dataset\n",
    "\n",
    "Import the dataset. Weather data can be requested from NOAA by filling out the form here: https://www.ncdc.noaa.gov/cdo-web/\n",
    "\n",
    "The data I selected was the Daily summary for Dulles International Airport in Washington, DC covering years 2015-2017.\n",
    "\n",
    "This included temperature, precipitation, wind speed and various weather codes that are explained in the NOAA documentation found here https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>6.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>16.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATION       DATE   AWND  PRCP  SNOW  TAVG  TMAX  TMIN  WT01  WT02  \\\n",
       "0     USW00093738 2015-01-01   6.93  0.00   0.0    28    42    18   0.0   0.0   \n",
       "1     USW00093738 2015-01-02   0.45  0.00   0.0    32    44    23   0.0   0.0   \n",
       "2     USW00093738 2015-01-03   2.01  0.56   0.0    33    38    24   1.0   0.0   \n",
       "3     USW00093738 2015-01-04  12.75  0.28   0.0    46    60    38   1.0   1.0   \n",
       "4     USW00093738 2015-01-05  16.11  0.00   0.0    40    46    24   0.0   0.0   \n",
       "...           ...        ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1091  USW00093738 2017-12-27  10.74  0.00   0.0    28    31    17   0.0   0.0   \n",
       "1092  USW00093738 2017-12-28   8.72  0.00   0.0    18    23     9   0.0   0.0   \n",
       "1093  USW00093738 2017-12-29   4.03  0.00   0.0    19    31    10   0.0   0.0   \n",
       "1094  USW00093738 2017-12-30   6.71  0.03   0.4    24    32    19   1.0   0.0   \n",
       "1095  USW00093738 2017-12-31   9.40  0.00   0.0    18    21    10   0.0   0.0   \n",
       "\n",
       "      WT03  WT04  WT05  WT06  WT08  WT09  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   1.0   0.0   1.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...  \n",
       "1091   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1092   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1093   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1094   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1095   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1096 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_dir, weather_file),  parse_dates=[1])\n",
    "# weather_df['DATE'] = weather_df['DATE'].dt.date\n",
    "\n",
    "# Replace Nulls will 0\n",
    "weather_df.fillna(0, inplace=True)\n",
    "\n",
    "##########################################\n",
    "## Add rename of columns\n",
    "\n",
    "# View the resulting dataframe\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Bike Dataset\n",
    "\n",
    "Import the datasets. Data Comes from Capital Bikeshare \n",
    "https://s3.amazonaws.com/capitalbikeshare-data/index.html\n",
    "https://www.capitalbikeshare.com/system-data\n",
    "\n",
    "The files are provided as csvs on a quarterly basis. Instead of manually merging. We can use the pandas library to concatenate the files into a single dataframe.\n",
    "\n",
    "The data provided details every single bike ride transaction in the Capital Bikeshare system across all stations. This is more detail than we need and we are just trying to find total rides per hour. We modify the timestamp to just include date and hour and then group the transactions by hour to get ride count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all bikeshare data files in the directory\n",
    "glob_pattern = os.path.join(raw_data_dir, f\"*{bike_file_suffix}\")\n",
    "dfs = [pd.read_csv(f, parse_dates=[1,2])\n",
    "        for f in glob(glob_pattern)]\n",
    "\n",
    "# Merge all files into a single dataframe\n",
    "bike_df = pd.concat(dfs).sort_values(by=['Start date'])\n",
    "\n",
    "\n",
    "####################\n",
    "# ADD REMOVAL of DURATION 86394.0 which is approx 60 days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data by hour intervals\n",
    "\n",
    "Use the groupby function to create a new dataframe that groups all rides by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2016-01-01 00:00:00     56\n",
       "2016-01-01 01:00:00    105\n",
       "2016-01-01 02:00:00     74\n",
       "2016-01-01 03:00:00     32\n",
       "2016-01-01 04:00:00     13\n",
       "                      ... \n",
       "2017-12-31 19:00:00     59\n",
       "2017-12-31 20:00:00     30\n",
       "2017-12-31 21:00:00     46\n",
       "2017-12-31 22:00:00     25\n",
       "2017-12-31 23:00:00     14\n",
       "Name: Bike number, Length: 17368, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncate timestamp to hour\n",
    "bike_hourly_df = bike_df.copy()\n",
    "bike_hourly_df['Timestamp'] = bike_hourly_df['Start date'].dt.floor('h') \n",
    "\n",
    "# Get total Rides per hour\n",
    "bike_hourly_df = bike_hourly_df.groupby(['Timestamp'], as_index = True)['Bike number'].count()\n",
    "\n",
    "# View the resulting dataframe\n",
    "bike_hourly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the datasets. They will be merged on Timestamp from the bike date and DATE from the weather data. This is done using the merge_asof function so that an exact match isn't required. Our bike data includes a time component which the weather data does not. We are essentially just matching the Timestamp to any DATE field that is less than or equal, in other words they are on the same date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ride count</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>56</td>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>105</td>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>74</td>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>32</td>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>USW00093738</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ride count      STATION       DATE  AWND  PRCP  SNOW  \\\n",
       "Timestamp                                                                   \n",
       "2016-01-01 00:00:00          56  USW00093738 2016-01-01   8.5   0.0   0.0   \n",
       "2016-01-01 01:00:00         105  USW00093738 2016-01-01   8.5   0.0   0.0   \n",
       "2016-01-01 02:00:00          74  USW00093738 2016-01-01   8.5   0.0   0.0   \n",
       "2016-01-01 03:00:00          32  USW00093738 2016-01-01   8.5   0.0   0.0   \n",
       "2016-01-01 04:00:00          13  USW00093738 2016-01-01   8.5   0.0   0.0   \n",
       "\n",
       "                     TAVG  TMAX  TMIN  WT01  WT02  WT03  WT04  WT05  WT06  \\\n",
       "Timestamp                                                                   \n",
       "2016-01-01 00:00:00    42    43    30   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2016-01-01 01:00:00    42    43    30   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2016-01-01 02:00:00    42    43    30   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2016-01-01 03:00:00    42    43    30   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2016-01-01 04:00:00    42    43    30   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     WT08  WT09  \n",
       "Timestamp                        \n",
       "2016-01-01 00:00:00   0.0   0.0  \n",
       "2016-01-01 01:00:00   0.0   0.0  \n",
       "2016-01-01 02:00:00   0.0   0.0  \n",
       "2016-01-01 03:00:00   0.0   0.0  \n",
       "2016-01-01 04:00:00   0.0   0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timestamp in bike_df are hourly, timestamp in weather_df are daily\n",
    "# Merge on nearest timestamp that is not greater than the Timestamp (i.e same day)\n",
    "\n",
    "data_df = pd.merge_asof(bike_hourly_df.reset_index(), weather_df, left_on='Timestamp', right_on = 'DATE', direction='backward').set_index(['Timestamp']).rename(columns = {'Bike number':'Ride count'})\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "We extrapolate attributes from the dataset to give us additional features (or variables) to use as inputs into our machine learning model. A timestamp may not correlate well with the Ride Count we are trying to predict but by extracting the day of the week we can predict spikes based on whether it is a work day or the weekend. The features I have added are \n",
    "\n",
    "* Hour\n",
    "* Day of week\n",
    "* Month\n",
    "* Day of year\n",
    "* Weekend (boolean flag to denote that it is saturday or sunday)\n",
    "* Holiday (boolean flag to denote that it is a major holiday that may effect bike demand. This is done by creating a holiday calendar object to account for shifting holidays)\n",
    "* Season (1 - Spring, 2 - Summer, 3 - Fall, 4 - Winter)\n",
    "\n",
    "Some of these feature columns will be dropped and not used in our model, but are useful for data analysis to find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Hour\n",
    "data_df.insert(3,'Hour', data_df.index.hour)\n",
    "# Add Day of week\n",
    "data_df.insert(4,'Day of week', data_df.index.dayofweek)\n",
    "# Add Month\n",
    "data_df.insert(5,'Month', data_df.index.month)\n",
    "# Add Day of year\n",
    "data_df.insert(6, 'Day of year', data_df.index.dayofyear)\n",
    "# Add weekend flag\n",
    "# true if day of week is 5 or 6 (saturday or sunday)\n",
    "days = [0, 0, 0, 0, 0, 1, 1]\n",
    "days_to_weekend = dict(zip(range(0,7), days))\n",
    "data_df.insert(7, 'Weekend', data_df['Day of week'].map(days_to_weekend))\n",
    "# Add Year\n",
    "data_df.insert(8,'Year', data_df.index.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Holiday Calendar\n",
    "from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday, \\\n",
    "    nearest_workday, previous_friday, next_monday, \\\n",
    "    USMartinLutherKingJr, USPresidentsDay, USMemorialDay, \\\n",
    "    USLaborDay, USThanksgivingDay\n",
    "\n",
    "from pandas import DateOffset\n",
    "from dateutil.relativedelta import FR, MO, SA, SU, TH, TU, WE\n",
    "import datetime as dt\n",
    "\n",
    "class USHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        Holiday('NewYearsDay', month=1, day=1, observance=nearest_workday),\n",
    "        USMartinLutherKingJr,\n",
    "        USPresidentsDay,\n",
    "        USMemorialDay,\n",
    "        Holiday('USIndependenceDay', month=7, day=4, observance=nearest_workday),\n",
    "        USLaborDay,\n",
    "        USThanksgivingDay,\n",
    "        Holiday('DayAfterThanksgiving', month=11, day=1, offset=[DateOffset(weekday=TH(4)), DateOffset(1)]),\n",
    "        Holiday('ChristmasEve', month=12, day=24, observance=previous_friday),\n",
    "        Holiday('Christmas', month=12, day=25, observance=next_monday)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_holidays(yearstart, yearend):\n",
    "    cal = USHolidayCalendar()\n",
    "\n",
    "    return cal.holidays(dt.datetime(yearstart-1, 12, 31), dt.datetime(yearend, 12, 31))\n",
    "\n",
    "holidays = get_holidays(2015,2017)\n",
    "\n",
    "data_df.insert(9,'Holiday',data_df['DATE'].astype(str).isin(holidays.astype(str)).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Seasons \n",
    "# Winter 1, Spring 2, Summer 3, Fall 4 based on month\n",
    "seasons = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1]\n",
    "month_to_season = dict(zip(range(1,13), seasons))\n",
    "data_df['Season'] = data_df['Month'].map(month_to_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can drop Date  and station columns after merge and feature engineering. WT09 is 0 for all columns and not needed\n",
    "data_df.drop(['DATE', 'STATION', 'WT09'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output prepared data\n",
    "The prepared data can be written to a CSV file for reuse or import into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_df.to_csv(os.path.join(clean_data_dir, clean_hourly_ride_file))\n",
    "# bike_df.to_csv(os.path.join(clean_data_dir, clean_transaction_file))\n",
    "weather_df.to_csv(os.path.join(clean_data_dir, clean_weather_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ride count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day of week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of year</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Year</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 19:00:00</th>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17368 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ride count  Hour  Day of week  Month  Day of year  \\\n",
       "Timestamp                                                                \n",
       "2016-01-01 00:00:00          56     0            4      1            1   \n",
       "2016-01-01 01:00:00         105     1            4      1            1   \n",
       "2016-01-01 02:00:00          74     2            4      1            1   \n",
       "2016-01-01 03:00:00          32     3            4      1            1   \n",
       "2016-01-01 04:00:00          13     4            4      1            1   \n",
       "...                         ...   ...          ...    ...          ...   \n",
       "2017-12-31 19:00:00          59    19            6     12          365   \n",
       "2017-12-31 20:00:00          30    20            6     12          365   \n",
       "2017-12-31 21:00:00          46    21            6     12          365   \n",
       "2017-12-31 22:00:00          25    22            6     12          365   \n",
       "2017-12-31 23:00:00          14    23            6     12          365   \n",
       "\n",
       "                     Weekend  Year  Holiday  AWND  PRCP  ...  TMAX  TMIN  \\\n",
       "Timestamp                                                ...               \n",
       "2016-01-01 00:00:00        0  2016        1   8.5   0.0  ...    43    30   \n",
       "2016-01-01 01:00:00        0  2016        1   8.5   0.0  ...    43    30   \n",
       "2016-01-01 02:00:00        0  2016        1   8.5   0.0  ...    43    30   \n",
       "2016-01-01 03:00:00        0  2016        1   8.5   0.0  ...    43    30   \n",
       "2016-01-01 04:00:00        0  2016        1   8.5   0.0  ...    43    30   \n",
       "...                      ...   ...      ...   ...   ...  ...   ...   ...   \n",
       "2017-12-31 19:00:00        1  2017        0   9.4   0.0  ...    21    10   \n",
       "2017-12-31 20:00:00        1  2017        0   9.4   0.0  ...    21    10   \n",
       "2017-12-31 21:00:00        1  2017        0   9.4   0.0  ...    21    10   \n",
       "2017-12-31 22:00:00        1  2017        0   9.4   0.0  ...    21    10   \n",
       "2017-12-31 23:00:00        1  2017        0   9.4   0.0  ...    21    10   \n",
       "\n",
       "                     WT01  WT02  WT03  WT04  WT05  WT06  WT08  Season  \n",
       "Timestamp                                                              \n",
       "2016-01-01 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2016-01-01 01:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2016-01-01 02:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2016-01-01 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2016-01-01 04:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "...                   ...   ...   ...   ...   ...   ...   ...     ...  \n",
       "2017-12-31 19:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2017-12-31 20:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2017-12-31 21:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2017-12-31 22:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "2017-12-31 23:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "\n",
       "[17368 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "Do some exploratory data analysis to make sure there aren't major anomalies in the data and to find patterns that can help in selecting features that will build the most effective model. Start with basic checks for nulls and any outlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ride count     0\n",
       "Hour           0\n",
       "Day of week    0\n",
       "Month          0\n",
       "Day of year    0\n",
       "Weekend        0\n",
       "Year           0\n",
       "Holiday        0\n",
       "AWND           0\n",
       "PRCP           0\n",
       "SNOW           0\n",
       "TAVG           0\n",
       "TMAX           0\n",
       "TMIN           0\n",
       "WT01           0\n",
       "WT02           0\n",
       "WT03           0\n",
       "WT04           0\n",
       "WT05           0\n",
       "WT06           0\n",
       "WT08           0\n",
       "Season         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ride count</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>408.323987</td>\n",
       "      <td>390.763603</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>312.00</td>\n",
       "      <td>611.00</td>\n",
       "      <td>1988.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>11.530804</td>\n",
       "      <td>6.915407</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>3.011861</td>\n",
       "      <td>1.998208</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>6.565523</td>\n",
       "      <td>3.426611</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of year</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>184.575484</td>\n",
       "      <td>104.912468</td>\n",
       "      <td>1.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>185.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>366.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekend</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.287080</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>2016.503052</td>\n",
       "      <td>0.500005</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>2017.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holiday</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.163769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWND</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>7.220630</td>\n",
       "      <td>3.668343</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.47</td>\n",
       "      <td>6.26</td>\n",
       "      <td>9.17</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRCP</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.101620</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNOW</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.336643</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAVG</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>57.585502</td>\n",
       "      <td>16.772340</td>\n",
       "      <td>16.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>87.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMAX</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>67.873273</td>\n",
       "      <td>17.781062</td>\n",
       "      <td>21.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMIN</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>47.062817</td>\n",
       "      <td>16.923598</td>\n",
       "      <td>7.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT01</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.383349</td>\n",
       "      <td>0.486216</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT02</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.039728</td>\n",
       "      <td>0.195326</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT03</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.099263</td>\n",
       "      <td>0.299023</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT04</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.097588</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT05</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.064254</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT06</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.073371</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WT08</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>0.053604</td>\n",
       "      <td>0.225242</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>17368.0</td>\n",
       "      <td>2.515488</td>\n",
       "      <td>1.111243</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count         mean         std      min      25%      50%  \\\n",
       "Ride count   17368.0   408.323987  390.763603     1.00    77.00   312.00   \n",
       "Hour         17368.0    11.530804    6.915407     0.00     6.00    12.00   \n",
       "Day of week  17368.0     3.011861    1.998208     0.00     1.00     3.00   \n",
       "Month        17368.0     6.565523    3.426611     1.00     4.00     7.00   \n",
       "Day of year  17368.0   184.575484  104.912468     1.00    94.00   185.00   \n",
       "Weekend      17368.0     0.287080    0.452412     0.00     0.00     0.00   \n",
       "Year         17368.0  2016.503052    0.500005  2016.00  2016.00  2017.00   \n",
       "Holiday      17368.0     0.027579    0.163769     0.00     0.00     0.00   \n",
       "AWND         17368.0     7.220630    3.668343     1.34     4.47     6.26   \n",
       "PRCP         17368.0     0.101620    0.280037     0.00     0.00     0.00   \n",
       "SNOW         17368.0     0.030827    0.336643     0.00     0.00     0.00   \n",
       "TAVG         17368.0    57.585502   16.772340    16.00    44.00    59.00   \n",
       "TMAX         17368.0    67.873273   17.781062    21.00    54.00    70.00   \n",
       "TMIN         17368.0    47.062817   16.923598     7.00    33.00    48.00   \n",
       "WT01         17368.0     0.383349    0.486216     0.00     0.00     0.00   \n",
       "WT02         17368.0     0.039728    0.195326     0.00     0.00     0.00   \n",
       "WT03         17368.0     0.099263    0.299023     0.00     0.00     0.00   \n",
       "WT04         17368.0     0.009615    0.097588     0.00     0.00     0.00   \n",
       "WT05         17368.0     0.004146    0.064254     0.00     0.00     0.00   \n",
       "WT06         17368.0     0.005412    0.073371     0.00     0.00     0.00   \n",
       "WT08         17368.0     0.053604    0.225242     0.00     0.00     0.00   \n",
       "Season       17368.0     2.515488    1.111243     1.00     2.00     3.00   \n",
       "\n",
       "                 75%      max  \n",
       "Ride count    611.00  1988.00  \n",
       "Hour           18.00    23.00  \n",
       "Day of week     5.00     6.00  \n",
       "Month          10.00    12.00  \n",
       "Day of year   275.00   366.00  \n",
       "Weekend         1.00     1.00  \n",
       "Year         2017.00  2017.00  \n",
       "Holiday         0.00     1.00  \n",
       "AWND            9.17    24.16  \n",
       "PRCP            0.03     2.82  \n",
       "SNOW            0.00     7.20  \n",
       "TAVG           73.00    87.00  \n",
       "TMAX           83.00   100.00  \n",
       "TMIN           62.00    78.00  \n",
       "WT01            1.00     1.00  \n",
       "WT02            0.00     1.00  \n",
       "WT03            0.00     1.00  \n",
       "WT04            0.00     1.00  \n",
       "WT05            0.00     1.00  \n",
       "WT06            0.00     1.00  \n",
       "WT08            0.00     1.00  \n",
       "Season          4.00     4.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start to explore the date using different charts to compare how different features may effect the Ride count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_2016 = data_df.where(data_df['Year']==2016)\n",
    "ridesbyday_bike_df = rides_2016.groupby(['Day of week'], as_index = False)['Ride count'].sum()\n",
    "x=ridesbyday_bike_df['Day of week']\n",
    "y=ridesbyday_bike_df['Ride count']\n",
    "plt.title('2016 Total Ride count by Day of week')\n",
    "plt.xlabel('Day of week')\n",
    "plt.xlabel('Total Rides')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=data_df, x='Day of week',y='Ride count')\n",
    "plt.title('Average Ride count by Day of week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=data_df, x='Day of week',y='Ride count',hue='Season')\n",
    "plt.title('Average Ride count by Day of week and season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=data_df, x='Hour',y='Ride count',hue='Season')\n",
    "plt.title('Average Ride count by hour and season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=data_df, x='Month',y='Ride count')\n",
    "plt.title('Average hourly Ride count by month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=data_df, x='Hour',y='Ride count',hue='Holiday',color=\"Or\")\n",
    "plt.title('Average rides per Hour on Holidays and non-holidays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=data_df, x='Hour',y='Ride count',hue='Weekend',color=\"Or\")\n",
    "plt.title('Average rides per hour on Weekends vs. Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=data_df.groupby(['TAVG']).sum()\n",
    "sns.barplot(data=temp_df,x=temp_df.index,y='Ride count')\n",
    "plt.xticks(rotation=270)\n",
    "plt.title('Distribution of total rides over daily average temperatures')\n",
    "plt.xlabel('Average Temperature F')\n",
    "plt.xticks(np.arange(temp_df.index.min(), temp_df.index.max()+1, 3.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmaps and pairplots are another good way of finding correlations in the data. The closer to an absolute value of 1 the more there is correlation. We can see that all features have a 1:1 correlation with themselves and the temperature values are all closely related.  We are looking for correlations with ride count.  These may not be the only items we choose as features as some items may not have a high correlation but are helpful for removing outlying data like the \"Holiday\" data point.\n",
    "\n",
    "Pairplots are another good way of viewing correlation between different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "sns.heatmap(data_df.corr(),square=True,annot=True,linewidths=.5,center=0,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_df[['Hour','TAVG','AWND','Season','Ride count']],diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training the model\n",
    "To train the model we need to split the data into training and test data. If the model trains on the same data that it is being tested against, it may falsely appear that our model is very accurate but that is only because it is already aware of what the test data looks like. When using this model for a real prediction it might not give us the result we expect. By testing against data that the model has not seen we get a better measure of accuracy.\n",
    "\n",
    "The training and test data is then split further into date that includes our feaures (or input variables) and labels (or outputs, the thing we want to predict). We have many columns in our source data, so we pick out only the features that we have found will correlate with the output through our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Season to one-hot variables\n",
    "data_df['Season'] = data_df['Season'].map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n",
    "data_df = pd.get_dummies(data_df, prefix='', prefix_sep='', columns=['Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(inplace=True)\n",
    "data_df.drop(['Timestamp'],axis=1, inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test data\n",
    "train_df = data_df.sample(frac=0.9, random_state=0)\n",
    "test_df = data_df.drop(train_df.index)\n",
    "\n",
    "train_features = train_df.loc[:,['Hour','TMAX','TMIN','Day of week','Month','Holiday','AWND','PRCP','Ride count']]\n",
    "test_features = test_df.loc[:,['Hour','TMAX','TMIN','Day of week','Month','Holiday','AWND','PRCP','Ride count']]\n",
    "\n",
    "train_labels = train_features.pop('Ride count')\n",
    "test_labels = test_features.pop('Ride count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data\n",
    "\n",
    "Our features work on different numeric scales. Some are a boolean 1 or 0 and some have much larger ranges for Temperature, Hour, or Wind speed. Normalizing minimizes the effect this may have on our model by converting them to the same range between -1 and 1. A normalizer object is created to keep track of this conversion and is an input into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.describe().transpose()[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train the model\n",
    "\n",
    "We are now ready to create our machine learning model and train it to make predictions. We will first define a couple functions to help us create the model and plot the loss (a type of measure for accuracy) to judge how well our model has been trained.\n",
    "\n",
    "The type of model we are creating uses the keras API and is a sequential model. It uses multiple hiddlen layers of neurons between the input and output layers and is therefore classified as a Deep Neural Network (DNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(normalizer, learning_rate):\n",
    "  model = keras.Sequential([\n",
    "      normalizer,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                metrics=[\n",
    "                    metrics.MeanAbsolutePercentageError(name='mean_absolute_percentage_error'),\n",
    "                    metrics.RootMeanSquaredError(name='root_mean_squared_error')\n",
    "                ]\n",
    "    )\n",
    "  return model\n",
    "\n",
    "def plot_loss(results):\n",
    "  plt.plot(results.history['loss'], label='loss')\n",
    "  plt.plot(results.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, max(results.history['loss'])])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Ride count]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plot_metric(results, metric, color='b'):\n",
    "  limits = [ 0, max(results.history[metric]), ]\n",
    "  plt.plot(results.history[metric], label=metric, color=color)\n",
    "  plt.ylim(limits)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Ride count]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.009\n",
    "model = create_model(normalizer, learning_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This statement can be used to reload from a checkpoint if you have saved the model to a file\n",
    "# dnn_model.load_weights('./models/checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now that the model is built, we can start training. We use a validation split, that further splits our training data set into training and validation data. In this way the model can check for loss against the validation data to judge how well it is doing during training instead of having to wait until the testing phase.\n",
    "\n",
    "We also set the number of epochs which are the number of training iterations we will run against the dataset. Batch size determines how many data points are processed at a time.\n",
    "\n",
    "The results of the training are captured so we can plot the improvement in the loss measurement over the training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = model.fit(\n",
    "    train_features, train_labels,\n",
    "#     steps_per_epoch=1000,\n",
    "#    batch_size =  16,\n",
    "    epochs=50,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_results)\n",
    "plot_metric(training_results, metric='root_mean_squared_error', color='r')\n",
    "plot_metric(training_results, metric='mean_absolute_percentage_error', color='g' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "\n",
    "Now that we have a model built. We can test it to see how it performs against the test dataset.\n",
    "\n",
    "We can then use the model to provide us with Ride count predictions based on the input features.  If we plot the true value from the test data against the predicted value we can see how accurate our model is. We are aiming to fit the diagonal line but overfitting can actually be a problem so if there is outlying data this is not necessarily a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['model'] = model.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [Ride count]')\n",
    "plt.ylabel('Predictions [Ride count]')\n",
    "lims = [-100, 2000]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the test results\n",
    "We can then do further evaluation of our test results to determine if we have a good model. First we will calculate the R2 score for the prediction. Scores closer to 1 are better.\n",
    "\n",
    "We then plot the difference between predictions and true values.\n",
    "\n",
    "We will also convert the difference values to a dataframe so we can gather statistical information on the distribution of values and look at the distribution of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(test_labels.values, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_predictions - test_labels.values)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = test_predictions - test_labels.values\n",
    "differences = pd.DataFrame(differences, columns=[\"Difference\"])\n",
    "differences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(differences)\n",
    "plt.xlabel(\"Ride Count variance between predicted and actual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "Once we are satisfied with the model or want to save our progress we can export the model weights to a local file to be restored later for further training. These are just the weights for the inputs based on training and doesn't contain the full model architecture.\n",
    "\n",
    "The second command will save the entire model including the architecture which is useful for importing into another application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./checkpoint/v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./bike_share_v1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_features.iloc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
